{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning 2 for Masters Students\n",
    "# Topic: Collaborative filtering vs. Content-based filtering\n",
    "### Group Members: Nurbek Bektursyn, Asset Kabdula\n",
    "### Date: 12.03.2024\n",
    "_____________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction\n",
    "- What problem does it address? <br/> <br/> \n",
    "The book recommdender system that uses both content-based filtering and collaborative filtering aims to solve a major problem in machine learning: the challenge of personalized suggestion. With an ever-increasing number of books available online and offline, people often find it difficult to decide what to read next. Therefore, our book recommder system recommends books that users are likely to appreciate based on their previous tastes and actions. \n",
    "<br/> <br/> \n",
    "- What is the intuition? <br/> <br/> \n",
    "**Popularity filtering (Baseline model):**  handles the \"cold start\" issue for new users for whom the system does not yet have enough data to offer tailored suggestions. _Intuition:_ highly rated by a big number of people are more likely to be enjoyed by others. This method implies that there is intrinsic value in what is popular, making such products potentially appealing to a large audience, including users with limited information about their tastes. <br/> <br/> \n",
    "**Content-based filtering:** handles the problem of suggestion by looking at the objects (books) themselves. It suggests books by assessing their content (genres, authors, language, and topics) and matching it to the user's previous choices. _Intuition:_ If a user like a book, they are more likely to appreciate subsequent books with similar content.\n",
    "<br/> <br/> \n",
    "**Collaborative filtering:** handles the issue of personalized suggestions by using a community of users' interests and actions. It is assumed that if users A and B have previously rated books similarly, then books loved by user A but not yet viewed by user B are likely to be of interest to user B. _Intuition:_ \"wisdom of crowds\" principle, which states that aggregating preferences across users might aid in the discovery of new preferences for each individual user.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExd2FrYjVzanczMjNyOWVkYm5wYnBiejIwenZqd3k5ZTg4N3Y1MGV1ayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3orieYVZvX5iOI4nu0/giphy.gif\" width=\"30%\" alt=\"Alt Text\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Your Terminal or Command Prompt\n",
    "\n",
    "Create a New Environment: \n",
    "conda create --name nlp python=3.12.2\n",
    "\n",
    "Activate the New Environment\n",
    "conda activate nlp\n",
    "\n",
    "Install Required Packages\n",
    "conda install pandas numpy matplotlib scikit-learn nltk scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "# Importing scikit-learn utilities for calculating cosine similarity and splitting datasets\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NLP (Natural Language Processing) tools for text preprocessing\n",
    "import nltk # the natural langauage toolkit, open-source NLP\n",
    "from nltk.corpus import stopwords # To remove stopwords from text data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # To convert text to TF-IDF vectors\n",
    "from nltk.tokenize import word_tokenize # For tokenizing strings into words\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer # For stemming and lemmatization of words\n",
    "import string # For handling string operations\n",
    "\n",
    "# Downloading necessary NLTK datasets for stopwords, wordnet, and tokenizers\n",
    "nltk.download('stopwords') # stopwords are common words that carry less meaning than keywords, usually removed from text\n",
    "nltk.download('wordnet') # wordnet is a lexical database of English words, used for text analysis\n",
    "nltk.download('punkt') # Punkt Tokenizer Models for tokenizing text documents\n",
    "\n",
    "# Importing libraries for handling sparse matrices and statistical correlations\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load book and rating data from CSV files into Pandas DataFrames\n",
    "books= pd.read_csv('../data/books.csv')\n",
    "ratings = pd.read_csv('../data/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>J.K. Rowling, Mary GrandPr√©</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>John Green</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>The Hobbit or There and Back Again</td>\n",
       "      <td>J.R.R. Tolkien</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Catcher in the Rye</td>\n",
       "      <td>J.D. Salinger</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Angels &amp; Demons</td>\n",
       "      <td>Dan Brown</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                            original_title  \\\n",
       "0        1                          The Hunger Games   \n",
       "1        2  Harry Potter and the Philosopher's Stone   \n",
       "2        3                                  Twilight   \n",
       "3        4                     To Kill a Mockingbird   \n",
       "4        5                          The Great Gatsby   \n",
       "5        6                    The Fault in Our Stars   \n",
       "6        7        The Hobbit or There and Back Again   \n",
       "7        8                    The Catcher in the Rye   \n",
       "8        9                          Angels & Demons    \n",
       "9       10                       Pride and Prejudice   \n",
       "\n",
       "                       authors  average_rating  \n",
       "0              Suzanne Collins            4.34  \n",
       "1  J.K. Rowling, Mary GrandPr√©            4.44  \n",
       "2              Stephenie Meyer            3.57  \n",
       "3                   Harper Lee            4.25  \n",
       "4          F. Scott Fitzgerald            3.89  \n",
       "5                   John Green            4.26  \n",
       "6               J.R.R. Tolkien            4.25  \n",
       "7                J.D. Salinger            3.79  \n",
       "8                    Dan Brown            3.85  \n",
       "9                  Jane Austen            4.24  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the books DataFrame by removing rows with missing 'original_title' values and selecting relevant columns\n",
    "books.dropna(subset=\"original_title\", inplace=True)\n",
    "books = books.loc[:,['book_id', 'original_title','authors','average_rating']]\n",
    "books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9415, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "1        117\n",
      "2         65\n",
      "3         91\n",
      "4        134\n",
      "5        100\n",
      "        ... \n",
      "53420    110\n",
      "53421    110\n",
      "53422    130\n",
      "53423     77\n",
      "53424    133\n",
      "Length: 53424, dtype: int64\n",
      "The minimum number of ratings per user: 19\n",
      "The maximum number of ratings per user: 200\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of ratings submitted by each user\n",
    "ratings_per_user = ratings.groupby('user_id').size()\n",
    "\n",
    "print(ratings_per_user)\n",
    "print(\"The minimum number of ratings per user:\", ratings_per_user.min())\n",
    "print(\"The maximum number of ratings per user:\", ratings_per_user.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25     96.0\n",
       "0.50    111.0\n",
       "0.75    128.0\n",
       "0.90    146.0\n",
       "0.95    157.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate specified percentiles for the number of ratings per user to understand the distribution\n",
    "percentiles = ratings_per_user.quantile([0.25, 0.5, 0.75, 0.9, 0.95])\n",
    "percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7674</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7857</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.34</td>\n",
       "      <td>2469</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.34</td>\n",
       "      <td>8146</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.34</td>\n",
       "      <td>1585</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id    original_title          authors  average_rating  user_id  rating\n",
       "0        1  The Hunger Games  Suzanne Collins            4.34     7674       5\n",
       "1        1  The Hunger Games  Suzanne Collins            4.34     7857       3\n",
       "2        1  The Hunger Games  Suzanne Collins            4.34     2469       4\n",
       "3        1  The Hunger Games  Suzanne Collins            4.34     8146       5\n",
       "4        1  The Hunger Games  Suzanne Collins            4.34     1585       4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge datasets considering only users with more than 157 ratings\n",
    "merged_data = pd.merge(books, ratings[ratings['user_id'].isin(ratings_per_user[ratings_per_user >= 157].index)], on='book_id', how='inner')\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449423, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224711\n",
      "224712\n"
     ]
    }
   ],
   "source": [
    "# Split the 'merged_data' DataFrame into training and test sets\n",
    "train, test = train_test_split(merged_data,\n",
    "                                   stratify=merged_data['user_id'], \n",
    "                                   test_size=0.50,\n",
    "                                   random_state=42)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>178</td>\n",
       "      <td>The Bell Jar</td>\n",
       "      <td>Sylvia Plath</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>186</td>\n",
       "      <td>The Other Boleyn Girl</td>\n",
       "      <td>Philippa Gregory</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>407</td>\n",
       "      <td>Bel Canto</td>\n",
       "      <td>Ann Patchett</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>451</td>\n",
       "      <td>Northanger Abbey</td>\n",
       "      <td>Jane Austen, Alfred MacAdam</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4473</td>\n",
       "      <td>Brick Lane</td>\n",
       "      <td>Monica Ali</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53366</th>\n",
       "      <td>12</td>\n",
       "      <td>Divergent</td>\n",
       "      <td>Veronica Roth</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53366</th>\n",
       "      <td>525</td>\n",
       "      <td>Pandemonium</td>\n",
       "      <td>Lauren Oliver</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53366</th>\n",
       "      <td>4424</td>\n",
       "      <td>inf</td>\n",
       "      <td>Sherrilyn Kenyon</td>\n",
       "      <td>4.04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53366</th>\n",
       "      <td>532</td>\n",
       "      <td>Batman: Year One</td>\n",
       "      <td>Frank Miller, David Mazzucchelli, Richmond Lew...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53366</th>\n",
       "      <td>581</td>\n",
       "      <td>Scarlet</td>\n",
       "      <td>Marissa Meyer</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449423 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_id         original_title  \\\n",
       "user_id                                   \n",
       "35           178           The Bell Jar   \n",
       "35           186  The Other Boleyn Girl   \n",
       "35           407              Bel Canto   \n",
       "35           451       Northanger Abbey   \n",
       "35          4473             Brick Lane   \n",
       "...          ...                    ...   \n",
       "53366         12              Divergent   \n",
       "53366        525            Pandemonium   \n",
       "53366       4424                    inf   \n",
       "53366        532       Batman: Year One   \n",
       "53366        581                Scarlet   \n",
       "\n",
       "                                                   authors  average_rating  \\\n",
       "user_id                                                                      \n",
       "35                                            Sylvia Plath            3.98   \n",
       "35                                        Philippa Gregory            4.04   \n",
       "35                                            Ann Patchett            3.92   \n",
       "35                             Jane Austen, Alfred MacAdam            3.80   \n",
       "35                                              Monica Ali            3.38   \n",
       "...                                                    ...             ...   \n",
       "53366                                        Veronica Roth            4.24   \n",
       "53366                                        Lauren Oliver            4.07   \n",
       "53366                                     Sherrilyn Kenyon            4.04   \n",
       "53366    Frank Miller, David Mazzucchelli, Richmond Lew...            4.23   \n",
       "53366                                        Marissa Meyer            4.30   \n",
       "\n",
       "         rating  \n",
       "user_id          \n",
       "35            3  \n",
       "35            3  \n",
       "35            3  \n",
       "35            3  \n",
       "35            3  \n",
       "...         ...  \n",
       "53366         4  \n",
       "53366         4  \n",
       "53366         5  \n",
       "53366         4  \n",
       "53366         3  \n",
       "\n",
       "[449423 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Indexing by user_id to speed up the searches during evaluation\n",
    "data_indexed = merged_data.sort_values(by='user_id').set_index('user_id')\n",
    "train_indexed = train.sort_values(by='user_id').set_index('user_id')\n",
    "test_indexed = test.sort_values(by='user_id').set_index('user_id')\n",
    "data_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(user_id, merged_data):\n",
    "    \"\"\"\n",
    "    Retrieves the set of items (book_ids) that a given user has interacted with.\n",
    "\n",
    "    This function identifies and returns all unique book IDs that a specific user has interacted with.\n",
    "    It is essential for ensuring that the recommendations made to the user do not include items\n",
    "    the user has already interacted with.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): The ID of the user for whom to retrieve interacted items.\n",
    "        merged_data (pd.DataFrame): The DataFrame containing user interactions with books.\n",
    "    \n",
    "    Returns:\n",
    "        set: A set of book IDs that the user has interacted with.\n",
    "    \"\"\"\n",
    "    interacted_items = merged_data.loc[user_id]['book_id']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "class ModelEvaluator:\n",
    "    \n",
    "    def get_not_interacted_items_sample(self, user_id, sample_size, seed=42):\n",
    "        \"\"\"\n",
    "        Generates a sample of non-interacted item IDs for a given user.\n",
    "        \n",
    "        Parameters:\n",
    "        - user_id: int or str, identifier for the user\n",
    "        - sample_size: int, size of the sample to generate\n",
    "        - seed: int, seed for the random number generator for reproducibility\n",
    "        \n",
    "        Returns:\n",
    "        - set, a set of non-interacted item IDs sampled randomly\n",
    "        \"\"\"\n",
    "        # Calculate a sample of non-interacted items for a user\n",
    "        interacted_items = get_items_interacted(user_id, data_indexed)\n",
    "        all_items = set(books['book_id']) # All available book IDs from the dataset\n",
    "        non_interacted_items = all_items - interacted_items # Determine non-interacted items\n",
    "        random.seed(seed) # Seed for reproducibility\n",
    "        non_interacted_items_sample = random.sample(list(non_interacted_items), sample_size)  # Random sample of non-interacted items\n",
    "        return set(non_interacted_items_sample)\n",
    "    \n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
    "        \"\"\"\n",
    "        Verifies if a specific item ID is within the top-N items of a recommendation list.\n",
    "        \n",
    "        Parameters:\n",
    "        - item_id: int or str, the item ID to verify\n",
    "        - recommended_items: list, a list of recommended item IDs\n",
    "        - topn: int, the number of top items to check against\n",
    "        \n",
    "        Returns:\n",
    "        - tuple (hit, index): hit is 1 if the item is within top-N, 0 otherwise; index is the item's index in the list or -1 if not found\n",
    "        \"\"\"\n",
    "        # Check if the interacted item is among the top-N recommended items\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c ==  item_id)\n",
    "        except:\n",
    "            index = -1 # Item not found among the top recommendation\n",
    "        hit = int(index in range(0, topn)) # Check if index is within the top-N\n",
    "        return hit, index\n",
    "    \n",
    "    def evaluate_model_for_user(self, model, user_id):\n",
    "        \"\"\"\n",
    "        Evaluates the model for a specific user by computing recall at different ranks.\n",
    "        \n",
    "        Parameters:\n",
    "        - model: the model to evaluate\n",
    "        - user_id: int or str, the user identifier\n",
    "        \n",
    "        Returns:\n",
    "        - dict, metrics including hits@5, hits@10, interacted count, recall@5, and recall@10\n",
    "        \"\"\"\n",
    "        # Evaluate model for a specific user, calculating recall at 5 and 10\n",
    "        interacted_values_testset = test_indexed.loc[user_id] # Get user's data from test set\n",
    "        # Determine if there are multiple interactions or just one\n",
    "        if type(interacted_values_testset['book_id']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['book_id'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['book_id'])])  \n",
    "        # Count of interacted items in test set\n",
    "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(user_id, \n",
    "                                               items_to_ignore=get_items_interacted(user_id, \n",
    "                                                                                    train_indexed), \n",
    "                                               topn=1000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "         # Loop through each interacted item in the test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(user_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "            \n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['book_id'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['book_id'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "        \n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "        # Compile metrics for the user\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "    \n",
    "    def evaluate_model(self, model):\n",
    "        \"\"\"\n",
    "        Evaluates a model across all users in the test set.\n",
    "        \n",
    "        Parameters:\n",
    "        - model: the model to be evaluated\n",
    "        \n",
    "        Returns:\n",
    "        - tuple, containing global metrics and a DataFrame of detailed results per user\n",
    "        \"\"\"\n",
    "        # Evaluate the model across all users in the test set\n",
    "        people_metrics = []\n",
    "        for idx, user_id in enumerate(list(test_indexed.index.unique().values)):\n",
    "            \n",
    "            person_metrics = self.evaluate_model_for_user(model, user_id)  \n",
    "            person_metrics['_person_id'] = user_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "        # Aggregate results\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Popularity Filtering (Baseline model)\n",
    "Same recommendtion for every user (except for removing the book that the user already read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3628</td>\n",
       "      <td>The Complete Calvin and Hobbes</td>\n",
       "      <td>Bill Watterson</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>862</td>\n",
       "      <td>Words of Radiance</td>\n",
       "      <td>Brandon Sanderson</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8854</td>\n",
       "      <td>Mark of the Lion Trilogy</td>\n",
       "      <td>Francine Rivers</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4483</td>\n",
       "      <td>It's a Magical World: A Calvin and Hobbes Coll...</td>\n",
       "      <td>Bill Watterson</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6361</td>\n",
       "      <td>There's Treasure Everywhere: A Calvin and Hobb...</td>\n",
       "      <td>Bill Watterson</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>422</td>\n",
       "      <td>Complete Harry Potter Boxed Set</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6920</td>\n",
       "      <td>The Indispensable Calvin and Hobbes: A Calvin ...</td>\n",
       "      <td>Bill Watterson</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3753</td>\n",
       "      <td>Harry Potter Collection (Harry Potter, #1-6)</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6590</td>\n",
       "      <td>The Authoritative Calvin and Hobbes</td>\n",
       "      <td>Bill Watterson</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1308</td>\n",
       "      <td>A Court of Mist and Fury</td>\n",
       "      <td>Sarah J. Maas</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                     original_title  \\\n",
       "0     3628                     The Complete Calvin and Hobbes   \n",
       "1      862                                  Words of Radiance   \n",
       "2     8854                           Mark of the Lion Trilogy   \n",
       "3     4483  It's a Magical World: A Calvin and Hobbes Coll...   \n",
       "4     6361  There's Treasure Everywhere: A Calvin and Hobb...   \n",
       "5      422                    Complete Harry Potter Boxed Set   \n",
       "6     6920  The Indispensable Calvin and Hobbes: A Calvin ...   \n",
       "7     3753       Harry Potter Collection (Harry Potter, #1-6)   \n",
       "8     6590                The Authoritative Calvin and Hobbes   \n",
       "9     1308                           A Court of Mist and Fury   \n",
       "\n",
       "             authors  average_rating  \n",
       "0     Bill Watterson            4.82  \n",
       "1  Brandon Sanderson            4.77  \n",
       "2    Francine Rivers            4.76  \n",
       "3     Bill Watterson            4.75  \n",
       "4     Bill Watterson            4.74  \n",
       "5       J.K. Rowling            4.74  \n",
       "6     Bill Watterson            4.73  \n",
       "7       J.K. Rowling            4.73  \n",
       "8     Bill Watterson            4.73  \n",
       "9      Sarah J. Maas            4.72  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the most popular items\n",
    "item_popularity_df = books.sort_values(by='average_rating', ascending=False).reset_index(drop=True)\n",
    "item_popularity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    \"\"\"\n",
    "    A recommender system that suggests popular items based on average ratings.\n",
    "    \n",
    "    Attributes:\n",
    "        MODEL_NAME (str): The name of the model.\n",
    "        popularity_df (DataFrame): A dataframe containing items with their popularity metrics.\n",
    "        items_df (DataFrame, optional): A dataframe containing additional item details.\n",
    "    \"\"\"\n",
    "    \n",
    "    MODEL_NAME = 'Popularity'\n",
    "    def __init__(self, popularity_df, items_df=None):\n",
    "        \"\"\"\n",
    "        Initializes the PopularityRecommender with necessary data.\n",
    "        \n",
    "        Parameters:\n",
    "            popularity_df (DataFrame): A dataframe containing the popularity data of the items.\n",
    "            items_df (DataFrame, optional): A dataframe containing detailed information about the items.\n",
    "        \"\"\"\n",
    "        self.popularity_df = popularity_df\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        \"\"\"\n",
    "        Returns the name of the model.\n",
    "        \n",
    "        Returns:\n",
    "            str: The name of the model.\n",
    "        \"\"\"\n",
    "        return self.MODEL_NAME\n",
    "    \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Recommends items that are not in the list of items to ignore, based on popularity.\n",
    "        \n",
    "        Parameters:\n",
    "            user_id (int or str): The user ID for whom the recommendations are to be made.\n",
    "            items_to_ignore (list, optional): A list of item IDs that should be ignored in the recommendations.\n",
    "            topn (int, optional): The number of recommendations to return.\n",
    "            verbose (bool, optional): If True, returns additional details about the items.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: The top N recommended items with their details based on the mode selected.\n",
    "        \n",
    "        Raises:\n",
    "            Exception: If 'items_df' is not provided when verbose mode is enabled.\n",
    "        \"\"\"\n",
    "        # Recommend the most popular items that the user hasn't seen yet.\n",
    "        recommendations_df = self.popularity_df[~self.popularity_df['book_id'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('average_rating', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'book_id', \n",
    "                                                          right_on = 'book_id')[['average_rating', 'book_id', 'original_title', 'authors']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "popularity_model = PopularityRecommender(item_popularity_df, books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Popularity recommendation model...\n",
      "2728 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Popularity', 'recall@5': 0.058728505820783934, 'recall@10': 0.10017266545622841}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>12381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>99</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>30944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>52036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>19729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>12874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>98</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>45554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>97</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.123711</td>\n",
       "      <td>37834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>97</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>15604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "792              7             10                99  0.070707   0.101010   \n",
       "1851            18             22                99  0.181818   0.222222   \n",
       "2687             8             15                98  0.081633   0.153061   \n",
       "1263             8              9                98  0.081633   0.091837   \n",
       "824              7             10                98  0.071429   0.102041   \n",
       "2456            10             11                98  0.102041   0.112245   \n",
       "2147             7             12                97  0.072165   0.123711   \n",
       "595              4              7                97  0.041237   0.072165   \n",
       "600              3              5                97  0.030928   0.051546   \n",
       "1023             6             11                97  0.061856   0.113402   \n",
       "\n",
       "      _person_id  \n",
       "792        12381  \n",
       "1851       30944  \n",
       "2687       52036  \n",
       "1263       19729  \n",
       "824        12874  \n",
       "2456       45554  \n",
       "2147       37834  \n",
       "595         9668  \n",
       "600         9731  \n",
       "1023       15604  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Popularity recommendation model...')\n",
    "pop_global_metrics, pop_detailed_results_df = model_evaluator.evaluate_model(popularity_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It achieved the Recall@5 of 0.0587, which means that about 5% of interacted items in test set were ranked by Popularity model among the top-5 items (from lists with 100 random items). And Recall@10 was even higher (10%), as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Show-case - Content-based filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/max/828/1*1b-yMSGZ1HfxvHiJCiPV7Q.png\" width=\"20%\" alt=\"Alt Text\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    \"\"\"\n",
    "    A preprocessing pipeline class for cleaning and normalizing text data\n",
    "\n",
    "    Attributes:\n",
    "        stop_words (set of str): A set containing stop words to be removed from the text.\n",
    "        lemmatizer (WordNetLemmatizer): An NLTK lemmatizer for reducing words to their lemma.\n",
    "        punctuation (str): A string of punctuation characters to be removed from the text.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the PreprocessingPipeline by setting up the stop words, lemmatizer, and punctuation.\n",
    "        \"\"\"\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.punctuation = string.punctuation\n",
    "\n",
    "    def tokenize_and_preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            text (str): The text to preprocess.\n",
    "\n",
    "        Returns:\n",
    "            list of str: A list of lemmatized words after preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        tokens = word_tokenize(text)\n",
    "        preprocessed_tokens = []\n",
    "        for token in tokens:\n",
    "            token = token.lower()  # Case folding\n",
    "            if token in self.stop_words or not token.isalpha():\n",
    "                continue  # Removing stop-words and unwanted characters\n",
    "            token = self.lemmatizer.lemmatize(token)  # Lemmatizing tokens\n",
    "            preprocessed_tokens.append(token)\n",
    "        return preprocessed_tokens\n",
    "    \n",
    "preprocessing_pipeline = PreprocessingPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9415x247 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13904 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     tokenizer=preprocessing_pipeline.tokenize_and_preprocess,\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000)\n",
    "item_ids = books['book_id'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(books['original_title'] + \" \" + books['authors'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_profile(item_id):\n",
    "    \"\"\"\n",
    "    Retrieves the TF-IDF vector for a specified item by its ID.\n",
    "\n",
    "    This function locates the index of the specified item using its ID and then extracts the \n",
    "    corresponding row from the TF-IDF matrix. This row (or item profile) represents the item's \n",
    "    textual features encoded as TF-IDF values, which can be used for calculating similarities \n",
    "    with other items or for making recommendations.\n",
    "\n",
    "    Parameters:\n",
    "        item_id (int): The ID of the item for which to retrieve the TF-IDF profile.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr.csr_matrix: The TF-IDF vector of the item as a sparse matrix.\n",
    "    \"\"\"\n",
    "    # Locate the index of the specified item_id in the list of all item IDs\n",
    "    idx = item_ids.index(item_id)\n",
    "    # Extract the TF-IDF vector for the specified item using its index\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    \n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    \"\"\"\n",
    "    Retrieves and aggregates the TF-IDF profiles for a list of item IDs.\n",
    "\n",
    "    This function uses a list comprehension to fetch the individual TF-IDF vectors \n",
    "    (item profiles) for each item ID provided in the list 'ids'. It then combines \n",
    "    these vectors into a single sparse matrix using vertical stacking (vstack), \n",
    "    which is useful for performing bulk operations like calculating similarities \n",
    "    or generating recommendations for multiple items at once.\n",
    "\n",
    "    Parameters:\n",
    "        ids (list of int): A list of item IDs for which to retrieve the TF-IDF profiles.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr.csr_matrix: A combined sparse matrix containing the TF-IDF vectors\n",
    "                                     for all specified items.\n",
    "    \"\"\"\n",
    "    # Generate a list of item profiles using a list comprehension\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    # Vertically stack the list of individual item profiles into one sparse matrix\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    \n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(user_id, interactions_indexed_df):\n",
    "    \"\"\"\n",
    "    Builds a normalized user profile based on their interactions and ratings.\n",
    "\n",
    "    This function calculates the weighted average of item profiles associated with the books\n",
    "    a user has interacted with, using the user's ratings as weights for averaging. The result\n",
    "    is then normalized to ensure uniformity in scale.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): The unique identifier for the user.\n",
    "    interactions_indexed_df (DataFrame): A pandas DataFrame indexed by user_id that contains \n",
    "                                         the book interactions along with user ratings.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The normalized weighted average profile for the specified user.\n",
    "    \"\"\"\n",
    "    interactions_person_df = interactions_indexed_df.loc[user_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['book_id'])\n",
    "    # Use the ratings as weights\n",
    "    user_item_ratings = np.array(interactions_person_df['rating']).reshape(-1,1)\n",
    "    # Calculate the weighted average of item profiles, using the ratings as weights.\n",
    "    user_item_ratings_weighted_avg = np.sum(user_item_profiles.multiply(user_item_ratings), axis=0) / np.sum(user_item_ratings)\n",
    "    # Normalize the weighted average to ensure a uniform scale.\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(np.asarray(user_item_ratings_weighted_avg))\n",
    "    \n",
    "    return user_profile_norm\n",
    "\n",
    "def build_users_profiles(train):\n",
    "    \"\"\"\n",
    "    Constructs user profiles for all users in the training dataset who have interacted with books.\n",
    "\n",
    "    This function iterates over unique user IDs in a training dataset, building a profile for each\n",
    "    user by aggregating their interactions and ratings with books. Each user's profile is created\n",
    "    using the `build_users_profile` function, which calculates a normalized weighted average\n",
    "    of item profiles based on the books the user has interacted with and their corresponding ratings.\n",
    "\n",
    "    The training dataset is filtered to only include interactions with books listed in a separate \n",
    "    books dataset.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping user IDs to their corresponding normalized weighted average profiles.\n",
    "    \"\"\"\n",
    "    interactions_indexed_df = train[train['book_id'] \\\n",
    "                                                   .isin(books['book_id'])].set_index('user_id')\n",
    "    user_profiles = {}\n",
    "    for user_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[user_id] = build_users_profile(user_id, interactions_indexed_df)\n",
    "    \n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2729"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profiles = build_users_profiles(train)\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 247)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smith</td>\n",
       "      <td>0.291435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "      <td>0.269649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ann</td>\n",
       "      <td>0.247159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jane</td>\n",
       "      <td>0.226299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anne</td>\n",
       "      <td>0.210372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>john</td>\n",
       "      <td>0.203345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brook</td>\n",
       "      <td>0.196299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>0.184692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>david</td>\n",
       "      <td>0.173840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>james</td>\n",
       "      <td>0.166999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sara</td>\n",
       "      <td>0.165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>little</td>\n",
       "      <td>0.164414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>robert</td>\n",
       "      <td>0.143590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>margaret</td>\n",
       "      <td>0.140877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>secret</td>\n",
       "      <td>0.139598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>george</td>\n",
       "      <td>0.138449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>agatha christie</td>\n",
       "      <td>0.120226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>christie</td>\n",
       "      <td>0.120226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>agatha</td>\n",
       "      <td>0.119810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anderson</td>\n",
       "      <td>0.110193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  relevance\n",
       "0             smith   0.291435\n",
       "1           william   0.269649\n",
       "2               ann   0.247159\n",
       "3              jane   0.226299\n",
       "4              anne   0.210372\n",
       "5              john   0.203345\n",
       "6             brook   0.196299\n",
       "7             white   0.184692\n",
       "8             david   0.173840\n",
       "9             james   0.166999\n",
       "10             sara   0.165289\n",
       "11           little   0.164414\n",
       "12           robert   0.143590\n",
       "13         margaret   0.140877\n",
       "14           secret   0.139598\n",
       "15           george   0.138449\n",
       "16  agatha christie   0.120226\n",
       "17         christie   0.120226\n",
       "18           agatha   0.119810\n",
       "19         anderson   0.110193"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 35\n",
    "myprofile = user_profiles[id]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[id].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \"\"\"\n",
    "    A content-based recommender system that suggests items based on the similarity between item profiles and a user's profile.\n",
    "    \n",
    "    Attributes:\n",
    "        MODEL_NAME (str): The name of the recommendation model.\n",
    "        items_df (DataFrame): A DataFrame containing detailed information about the items.\n",
    "    \"\"\"\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        \"\"\"\n",
    "        Initializes the ContentBasedRecommender with item details.\n",
    "        \n",
    "        Parameters:\n",
    "            items_df (DataFrame, optional): A DataFrame containing details about each item.\n",
    "        \"\"\"\n",
    "        self.item_ids = item_ids    #\n",
    "        self.items_df = items_df    #\n",
    "        # self.user_profiles \n",
    "        # self.item_profiles\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        \"\"\"\n",
    "        Returns the name of the recommendation model.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.MODEL_NAME\n",
    "    \n",
    "    def _get_similar_items_to_user_profile(self, user_id, topn=1000):    # all the parameters should go in here  tfidf_matrix\n",
    "        \"\"\"\n",
    "        Computes the cosine similarity between a specific user's profile and all item profiles, returning the top N similar items.\n",
    "        \n",
    "        Parameters:\n",
    "            user_id (int or str): The user identifier.\n",
    "            topn (int): Number of top similar items to return.\n",
    "        \n",
    "        Returns:\n",
    "            list of tuples: A list of tuples, each containing an item ID and its similarity score.\n",
    "        \"\"\"\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[user_id], tfidf_matrix)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "    \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Generates a list of recommended items for a user, excluding items the user has already interacted with.\n",
    "        \n",
    "        Parameters:\n",
    "            user_id (int or str): The user identifier.\n",
    "            items_to_ignore (list of int/str, optional): List of item IDs to ignore in the recommendations.\n",
    "            topn (int, optional): The number of recommendations to return.\n",
    "            verbose (bool, optional): If True, includes detailed information about each item in the recommendations.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: A DataFrame containing the recommended items along with their recommendation strength.\n",
    "        \n",
    "        Raises:\n",
    "            Exception: If 'items_df' is not provided when verbose mode is enabled.\n",
    "        \"\"\"\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['book_id', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['average_rating', 'book_id', 'original_title', 'authors']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "2728 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.20806187475524227, 'recall@10': 0.2816672006835416}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>99</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>12381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>99</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>30944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>0.234694</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>52036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>19729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>98</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>12874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>45554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>97</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.123711</td>\n",
       "      <td>37834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>97</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>97</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.350515</td>\n",
       "      <td>9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>97</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>15604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "792              7             16                99  0.070707   0.161616   \n",
       "1851            19             36                99  0.191919   0.363636   \n",
       "2687            23             31                98  0.234694   0.316327   \n",
       "1263            14             21                98  0.142857   0.214286   \n",
       "824              8             14                98  0.081633   0.142857   \n",
       "2456            13             20                98  0.132653   0.204082   \n",
       "2147             7             12                97  0.072165   0.123711   \n",
       "595              5             15                97  0.051546   0.154639   \n",
       "600             23             34                97  0.237113   0.350515   \n",
       "1023            16             22                97  0.164948   0.226804   \n",
       "\n",
       "      _person_id  \n",
       "792        12381  \n",
       "1851       30944  \n",
       "2687       52036  \n",
       "1263       19729  \n",
       "824        12874  \n",
       "2456       45554  \n",
       "2147       37834  \n",
       "595         9668  \n",
       "600         9731  \n",
       "1023       15604  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With personalized recommendations of content-based filtering model, we have a Recall@5 of 0.208, which means that about 20% of interacted items in test set were ranked by this model among the top-5 items (from lists with 100 random items). And Recall@10 was 0.261 (26%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show-case - Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://cdn-images-1.medium.com/max/1000/0*gJ8CeGoD9IAHzSmb.png\" width=\"30%\" alt=\"Alt Text\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 8578 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id  1      2      3      4      5      6      7      8      9      10     \\\n",
       "user_id                                                                         \n",
       "35        0.00   0.00   0.00   0.00    0.0    0.0   0.00   0.00   0.00    0.0   \n",
       "75        4.34   0.00   0.00   0.00    0.0    0.0   0.00   3.79   0.00    0.0   \n",
       "143       4.34   0.00   3.57   0.00    0.0    0.0   0.00   0.00   3.85    0.0   \n",
       "145       0.00   0.00   3.57   0.00    0.0    0.0   0.00   0.00   0.00    0.0   \n",
       "173       0.00   4.44   0.00   0.00    0.0    0.0   0.00   0.00   3.85    0.0   \n",
       "178       4.34   0.00   0.00   0.00    0.0    0.0   0.00   0.00   0.00    0.0   \n",
       "202       0.00   0.00   3.57   0.00    0.0    0.0   4.25   3.79   3.85    0.0   \n",
       "215       0.00   0.00   0.00   0.00    0.0    0.0   4.25   0.00   0.00    0.0   \n",
       "230       0.00   0.00   0.00   4.25    0.0    0.0   0.00   0.00   0.00    0.0   \n",
       "247       0.00   0.00   0.00   4.25    0.0    0.0   0.00   0.00   0.00    0.0   \n",
       "\n",
       "book_id  ...  9990   9991   9992   9993   9994   9995   9997   9998   9999   \\\n",
       "user_id  ...                                                                  \n",
       "35       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "75       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "143      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "145      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "173      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "178      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "202      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "215      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "230      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "247      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "book_id  10000  \n",
       "user_id         \n",
       "35         0.0  \n",
       "75         0.0  \n",
       "143        0.0  \n",
       "145        0.0  \n",
       "173        0.0  \n",
       "178        0.0  \n",
       "202        0.0  \n",
       "215        0.0  \n",
       "230        0.0  \n",
       "247        0.0  \n",
       "\n",
       "[10 rows x 8578 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a sparse pivot table with users in rows and items in columns\n",
    "users_items_pivot_matrix_df = train.pivot(index='user_id', \n",
    "                                                          columns='book_id', \n",
    "                                                          values='average_rating').fillna(0)\n",
    "\n",
    "users_items_pivot_matrix_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data: user_id, book_id, rating\n",
    "#matrix = sparse matrix with zeros only\n",
    "#for row in data:\n",
    "#    matrix[user_id, book_id] =  rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [4.34, 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [4.34, 0.  , 3.57, ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items_pivot_matrix = users_items_pivot_matrix_df.to_numpy()  # transform into a sparse matrix\n",
    "users_items_pivot_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 75, 143, 145, 173, 178, 202, 215, 230, 247]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_ids = list(users_items_pivot_matrix_df.index)\n",
    "users_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2729x8578 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 224711 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items_pivot_sparse_matrix = csr_matrix(users_items_pivot_matrix)\n",
    "users_items_pivot_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of factors to factor the user-item matrix.\n",
    "NUMBER_OF_FACTORS_MF = 15\n",
    "#Performs matrix factorization of the original user item matrix\n",
    "#U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)\n",
    "U, sigma, Vt = svds(users_items_pivot_sparse_matrix, k = NUMBER_OF_FACTORS_MF)   #Partial singular value decomposition of a sparse matrix. \n",
    "                                            #Compute the largest or smallest k singular values and corresponding singular vectors of a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2729, 15)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 8578)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.diag(sigma)\n",
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68126704e-01,  3.73080326e-01,  7.13916007e-01, ...,\n",
       "         1.40045007e-03,  3.80923788e-03, -5.22281137e-04],\n",
       "       [ 4.98148731e+00,  8.57049256e-01,  9.44652284e-01, ...,\n",
       "        -1.78879747e-03,  3.15692209e-02, -2.37913185e-03],\n",
       "       [ 3.65554079e+00,  8.29523199e-01,  1.12375004e+00, ...,\n",
       "        -5.85387280e-04,  1.43820712e-02, -6.68687932e-03],\n",
       "       ...,\n",
       "       [ 4.08167404e-01,  8.72931119e-01, -4.79548584e-01, ...,\n",
       "         1.06585888e-03,  5.44602676e-03,  1.83438305e-02],\n",
       "       [ 2.70803416e+00,  8.27769404e-01,  1.18463564e+00, ...,\n",
       "        -2.88675268e-03, -5.24352514e-03,  2.62938433e-02],\n",
       "       [-9.96656239e-01,  1.88038289e+00,  1.41898875e+00, ...,\n",
       "         4.12717504e-03, -3.76672125e-03,  3.12909869e-03]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "all_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the predicted ratings for all users to a range of 0 to 1. This scaling helps in managing different scales \n",
    "# of raw ratings data by bringing them to a uniform scale. The minimum rating value becomes 0, and the maximum rating value becomes 1.\n",
    "all_user_predicted_ratings_norm = (all_user_predicted_ratings - all_user_predicted_ratings.min()) / (all_user_predicted_ratings.max() - all_user_predicted_ratings.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>35</th>\n",
       "      <th>75</th>\n",
       "      <th>143</th>\n",
       "      <th>145</th>\n",
       "      <th>173</th>\n",
       "      <th>178</th>\n",
       "      <th>202</th>\n",
       "      <th>215</th>\n",
       "      <th>230</th>\n",
       "      <th>247</th>\n",
       "      <th>...</th>\n",
       "      <th>53145</th>\n",
       "      <th>53165</th>\n",
       "      <th>53173</th>\n",
       "      <th>53245</th>\n",
       "      <th>53279</th>\n",
       "      <th>53281</th>\n",
       "      <th>53292</th>\n",
       "      <th>53293</th>\n",
       "      <th>53318</th>\n",
       "      <th>53366</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319792</td>\n",
       "      <td>0.880142</td>\n",
       "      <td>0.725781</td>\n",
       "      <td>0.542438</td>\n",
       "      <td>0.308014</td>\n",
       "      <td>0.676605</td>\n",
       "      <td>0.318696</td>\n",
       "      <td>0.207508</td>\n",
       "      <td>0.179464</td>\n",
       "      <td>0.223074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814943</td>\n",
       "      <td>0.392765</td>\n",
       "      <td>0.321624</td>\n",
       "      <td>0.229526</td>\n",
       "      <td>0.398921</td>\n",
       "      <td>0.428731</td>\n",
       "      <td>0.248550</td>\n",
       "      <td>0.347736</td>\n",
       "      <td>0.615476</td>\n",
       "      <td>0.184193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343651</td>\n",
       "      <td>0.399993</td>\n",
       "      <td>0.396788</td>\n",
       "      <td>0.141346</td>\n",
       "      <td>0.717227</td>\n",
       "      <td>0.335033</td>\n",
       "      <td>0.615235</td>\n",
       "      <td>0.480683</td>\n",
       "      <td>0.329444</td>\n",
       "      <td>0.462868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716402</td>\n",
       "      <td>0.457841</td>\n",
       "      <td>0.274907</td>\n",
       "      <td>0.314013</td>\n",
       "      <td>0.278259</td>\n",
       "      <td>0.430628</td>\n",
       "      <td>0.332493</td>\n",
       "      <td>0.401842</td>\n",
       "      <td>0.396584</td>\n",
       "      <td>0.519125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383330</td>\n",
       "      <td>0.410191</td>\n",
       "      <td>0.431041</td>\n",
       "      <td>0.319546</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.338088</td>\n",
       "      <td>0.377241</td>\n",
       "      <td>0.377506</td>\n",
       "      <td>0.298311</td>\n",
       "      <td>0.276645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544426</td>\n",
       "      <td>0.524592</td>\n",
       "      <td>0.308424</td>\n",
       "      <td>0.319927</td>\n",
       "      <td>0.332474</td>\n",
       "      <td>0.410191</td>\n",
       "      <td>0.472912</td>\n",
       "      <td>0.244392</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.465411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304516</td>\n",
       "      <td>0.348477</td>\n",
       "      <td>0.274575</td>\n",
       "      <td>0.429150</td>\n",
       "      <td>0.418609</td>\n",
       "      <td>0.279213</td>\n",
       "      <td>0.589769</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.489785</td>\n",
       "      <td>0.595688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453546</td>\n",
       "      <td>0.466856</td>\n",
       "      <td>0.442649</td>\n",
       "      <td>0.395112</td>\n",
       "      <td>0.317190</td>\n",
       "      <td>0.534497</td>\n",
       "      <td>0.468208</td>\n",
       "      <td>0.290402</td>\n",
       "      <td>0.408185</td>\n",
       "      <td>0.529889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.296541</td>\n",
       "      <td>0.435863</td>\n",
       "      <td>0.372541</td>\n",
       "      <td>0.465252</td>\n",
       "      <td>0.437536</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>0.476124</td>\n",
       "      <td>0.444381</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>0.457027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407951</td>\n",
       "      <td>0.377026</td>\n",
       "      <td>0.340480</td>\n",
       "      <td>0.318417</td>\n",
       "      <td>0.388666</td>\n",
       "      <td>0.507850</td>\n",
       "      <td>0.453101</td>\n",
       "      <td>0.239515</td>\n",
       "      <td>0.366030</td>\n",
       "      <td>0.427943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.312493</td>\n",
       "      <td>0.381530</td>\n",
       "      <td>0.421182</td>\n",
       "      <td>0.288339</td>\n",
       "      <td>0.588221</td>\n",
       "      <td>0.372164</td>\n",
       "      <td>0.310786</td>\n",
       "      <td>0.300384</td>\n",
       "      <td>0.451602</td>\n",
       "      <td>0.289183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319311</td>\n",
       "      <td>0.518667</td>\n",
       "      <td>0.295601</td>\n",
       "      <td>0.379540</td>\n",
       "      <td>0.428033</td>\n",
       "      <td>0.340980</td>\n",
       "      <td>0.455691</td>\n",
       "      <td>0.278449</td>\n",
       "      <td>0.358576</td>\n",
       "      <td>0.559451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.327384</td>\n",
       "      <td>0.362367</td>\n",
       "      <td>0.402113</td>\n",
       "      <td>0.274259</td>\n",
       "      <td>0.444386</td>\n",
       "      <td>0.326235</td>\n",
       "      <td>0.480839</td>\n",
       "      <td>0.535896</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.324260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496192</td>\n",
       "      <td>0.369638</td>\n",
       "      <td>0.246093</td>\n",
       "      <td>0.295427</td>\n",
       "      <td>0.382038</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.438469</td>\n",
       "      <td>0.239592</td>\n",
       "      <td>0.372114</td>\n",
       "      <td>0.400534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.278512</td>\n",
       "      <td>0.397557</td>\n",
       "      <td>0.349411</td>\n",
       "      <td>0.441087</td>\n",
       "      <td>0.409655</td>\n",
       "      <td>0.317775</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.436490</td>\n",
       "      <td>0.426586</td>\n",
       "      <td>0.503652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395672</td>\n",
       "      <td>0.392362</td>\n",
       "      <td>0.402805</td>\n",
       "      <td>0.352758</td>\n",
       "      <td>0.338758</td>\n",
       "      <td>0.506399</td>\n",
       "      <td>0.428616</td>\n",
       "      <td>0.282545</td>\n",
       "      <td>0.377733</td>\n",
       "      <td>0.443306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.360703</td>\n",
       "      <td>0.413792</td>\n",
       "      <td>0.419337</td>\n",
       "      <td>0.354076</td>\n",
       "      <td>0.362830</td>\n",
       "      <td>0.317345</td>\n",
       "      <td>0.448181</td>\n",
       "      <td>0.413939</td>\n",
       "      <td>0.345953</td>\n",
       "      <td>0.347785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435695</td>\n",
       "      <td>0.392005</td>\n",
       "      <td>0.403737</td>\n",
       "      <td>0.350820</td>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.457621</td>\n",
       "      <td>0.368488</td>\n",
       "      <td>0.319652</td>\n",
       "      <td>0.385420</td>\n",
       "      <td>0.305039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.401406</td>\n",
       "      <td>0.359145</td>\n",
       "      <td>0.346491</td>\n",
       "      <td>0.340584</td>\n",
       "      <td>0.446384</td>\n",
       "      <td>0.301153</td>\n",
       "      <td>0.384655</td>\n",
       "      <td>0.445366</td>\n",
       "      <td>0.429016</td>\n",
       "      <td>0.371018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467115</td>\n",
       "      <td>0.383492</td>\n",
       "      <td>0.257826</td>\n",
       "      <td>0.303278</td>\n",
       "      <td>0.400565</td>\n",
       "      <td>0.484492</td>\n",
       "      <td>0.391758</td>\n",
       "      <td>0.248869</td>\n",
       "      <td>0.308997</td>\n",
       "      <td>0.389472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 2729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            35        75        143       145       173       178       202    \\\n",
       "book_id                                                                         \n",
       "1        0.319792  0.880142  0.725781  0.542438  0.308014  0.676605  0.318696   \n",
       "2        0.343651  0.399993  0.396788  0.141346  0.717227  0.335033  0.615235   \n",
       "3        0.383330  0.410191  0.431041  0.319546  0.381422  0.338088  0.377241   \n",
       "4        0.304516  0.348477  0.274575  0.429150  0.418609  0.279213  0.589769   \n",
       "5        0.296541  0.435863  0.372541  0.465252  0.437536  0.343002  0.476124   \n",
       "6        0.312493  0.381530  0.421182  0.288339  0.588221  0.372164  0.310786   \n",
       "7        0.327384  0.362367  0.402113  0.274259  0.444386  0.326235  0.480839   \n",
       "8        0.278512  0.397557  0.349411  0.441087  0.409655  0.317775  0.505556   \n",
       "9        0.360703  0.413792  0.419337  0.354076  0.362830  0.317345  0.448181   \n",
       "10       0.401406  0.359145  0.346491  0.340584  0.446384  0.301153  0.384655   \n",
       "\n",
       "            215       230       247    ...     53145     53165     53173  \\\n",
       "book_id                                ...                                 \n",
       "1        0.207508  0.179464  0.223074  ...  0.814943  0.392765  0.321624   \n",
       "2        0.480683  0.329444  0.462868  ...  0.716402  0.457841  0.274907   \n",
       "3        0.377506  0.298311  0.276645  ...  0.544426  0.524592  0.308424   \n",
       "4        0.465026  0.489785  0.595688  ...  0.453546  0.466856  0.442649   \n",
       "5        0.444381  0.434190  0.457027  ...  0.407951  0.377026  0.340480   \n",
       "6        0.300384  0.451602  0.289183  ...  0.319311  0.518667  0.295601   \n",
       "7        0.535896  0.347800  0.324260  ...  0.496192  0.369638  0.246093   \n",
       "8        0.436490  0.426586  0.503652  ...  0.395672  0.392362  0.402805   \n",
       "9        0.413939  0.345953  0.347785  ...  0.435695  0.392005  0.403737   \n",
       "10       0.445366  0.429016  0.371018  ...  0.467115  0.383492  0.257826   \n",
       "\n",
       "            53245     53279     53281     53292     53293     53318     53366  \n",
       "book_id                                                                        \n",
       "1        0.229526  0.398921  0.428731  0.248550  0.347736  0.615476  0.184193  \n",
       "2        0.314013  0.278259  0.430628  0.332493  0.401842  0.396584  0.519125  \n",
       "3        0.319927  0.332474  0.410191  0.472912  0.244392  0.438129  0.465411  \n",
       "4        0.395112  0.317190  0.534497  0.468208  0.290402  0.408185  0.529889  \n",
       "5        0.318417  0.388666  0.507850  0.453101  0.239515  0.366030  0.427943  \n",
       "6        0.379540  0.428033  0.340980  0.455691  0.278449  0.358576  0.559451  \n",
       "7        0.295427  0.382038  0.382600  0.438469  0.239592  0.372114  0.400534  \n",
       "8        0.352758  0.338758  0.506399  0.428616  0.282545  0.377733  0.443306  \n",
       "9        0.350820  0.281673  0.457621  0.368488  0.319652  0.385420  0.305039  \n",
       "10       0.303278  0.400565  0.484492  0.391758  0.248869  0.308997  0.389472  \n",
       "\n",
       "[10 rows x 2729 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the reconstructed matrix back to a Pandas dataframe\n",
    "cf_preds_df = pd.DataFrame(all_user_predicted_ratings_norm, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
    "cf_preds_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2729"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cf_preds_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRecommender:\n",
    "    \"\"\"\n",
    "    A recommender system class that implements Collaborative Filtering based on a precomputed prediction matrix.\n",
    "    \n",
    "    Attributes:\n",
    "        MODEL_NAME (str): The name of the model, indicating the type of recommendation algorithm used.\n",
    "        cf_predictions_df (DataFrame): A DataFrame containing the collaborative filtering predictions.\n",
    "        items_df (DataFrame, optional): A DataFrame containing details about the items.\n",
    "    \"\"\"\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative Filtering'\n",
    "    \n",
    "    def __init__(self, cf_predictions_df, items_df=None):\n",
    "        \"\"\"\n",
    "        Initializes the CFRecommender with necessary data.\n",
    "        \n",
    "        Parameters:\n",
    "            cf_predictions_df (DataFrame): A DataFrame containing user-item rating predictions.\n",
    "            items_df (DataFrame, optional): A DataFrame containing details about each item.\n",
    "        \"\"\"\n",
    "        self.cf_predictions_df = cf_predictions_df\n",
    "        self.items_df = items_df\n",
    "\n",
    "\n",
    "    def get_model_name(self):\n",
    "        \"\"\"\n",
    "        Returns the name of the recommendation model.\n",
    "        \"\"\"\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        \"\"\"\n",
    "        Generates a list of recommended items for a user based on collaborative filtering predictions, excluding items the user has already interacted with.\n",
    "        \n",
    "        Parameters:\n",
    "            user_id (int or str): The user identifier.\n",
    "            items_to_ignore (list of int/str, optional): List of item IDs to ignore in the recommendations.\n",
    "            topn (int, optional): The number of recommendations to return.\n",
    "            verbose (bool, optional): If True, includes detailed information about each recommended item.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: A DataFrame containing the recommended items along with their recommendation strengths.\n",
    "        \n",
    "        Raises:\n",
    "            Exception: If 'items_df' is not provided when verbose mode is enabled.\n",
    "        \"\"\"\n",
    "        # Get and sort the user's predictions\n",
    "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n",
    "                                    .reset_index().rename(columns={user_id: 'recStrength'})\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['book_id'].isin(items_to_ignore)] \\\n",
    "                               .sort_values('recStrength', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'book_id', \n",
    "                                                          right_on = 'book_id')[['recStrength', 'book_id',  'original_title', 'authors']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "cf_recommender_model = CFRecommender(cf_preds_df, books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Collaborative Filtering (SVD Matrix Factorization) model...\n",
      "2728 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'recall@5': 0.6342340417957207, 'recall@10': 0.7513305920467087}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>99</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>12381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>83</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>30944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>52036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>71</td>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>19729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>12874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>95</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>45554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>97</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>37834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "      <td>97</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>97</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>77</td>\n",
       "      <td>85</td>\n",
       "      <td>97</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>15604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "792             82             90                99  0.828283   0.909091   \n",
       "1851            83             92                99  0.838384   0.929293   \n",
       "2687            76             88                98  0.775510   0.897959   \n",
       "1263            71             84                98  0.724490   0.857143   \n",
       "824             85             89                98  0.867347   0.908163   \n",
       "2456            95             97                98  0.969388   0.989796   \n",
       "2147            67             78                97  0.690722   0.804124   \n",
       "595             53             70                97  0.546392   0.721649   \n",
       "600             81             91                97  0.835052   0.938144   \n",
       "1023            77             85                97  0.793814   0.876289   \n",
       "\n",
       "      _person_id  \n",
       "792        12381  \n",
       "1851       30944  \n",
       "2687       52036  \n",
       "1263       19729  \n",
       "824        12874  \n",
       "2456       45554  \n",
       "2147       37834  \n",
       "595         9668  \n",
       "600         9731  \n",
       "1023       15604  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
    "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
    "cf_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Collaborative Filtering model (SVD matrix factorization), we observe that we got Recall@5 (63%) and Recall@10 (75%) values, much higher than Popularity model and Content-Based model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>0.058729</td>\n",
       "      <td>0.100173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Content-Based</th>\n",
       "      <td>0.208062</td>\n",
       "      <td>0.281667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collaborative Filtering</th>\n",
       "      <td>0.634234</td>\n",
       "      <td>0.751331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         recall@5  recall@10\n",
       "modelName                                   \n",
       "Popularity               0.058729   0.100173\n",
       "Content-Based            0.208062   0.281667\n",
       "Collaborative Filtering  0.634234   0.751331"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [cb_global_metrics, pop_global_metrics, cf_global_metrics]\n",
    "global_metrics_df = pd.DataFrame([pop_global_metrics, cb_global_metrics, cf_global_metrics]) \\\n",
    "                        .set_index('modelName')\n",
    "global_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = global_metrics_df.transpose().plot(kind='bar', figsize=(15,8), title='Metrics Comparison')\n",
    "# Setting x-axis labels to horizontal\n",
    "plt.xticks(rotation=0)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.3f\" % p.get_height(), \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 10), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Caution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation method is based on the simplistic assumption that books that the user has not previously interacted with are irrelevant. However, it is crucial to note that this may not truly reflect reality, since the lack of engagement might be due to the user's unfamiliarity with these books instead of a true indifference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Summary\n",
    "Book recommender systems demonstrate the power of machine learning (ML) applications for improving user experience. In this notebook, we've looked at different Recommender Systems techniques on [goodbooks-10k](https://www.kaggle.com/datasets/zygmunt/goodbooks-10k) dataset. The Collaborative filtering tenchnique apeared to be the best compared to Popularity and Content-based filtering techniques, delivering personalized book recommendations that resonate with individual users' tastes and reading histories. However, there is still room for improvement like integrating a hubrid method (Collaborative + Content-based filtering) into the analysis or/and making the analysis more interactive, making the system more dynamic and responsive to individual needs. <br><br>\n",
    "Looking ahead, incorporating these improvements promises not just to improve the accuracy and relevance of book suggestions, but also to open the way for more sophisticated, adaptive, and user-centric recommender systems. The path of refining and inventing in the field of recommender systems continues, and the incorporation of hybrid models and interactive components promises interesting future steps in making the digital reading experience more customized and engaging for readers throughout the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: References and Resources\n",
    "1. https://www.kaggle.com/code/niharika41298/netflix-vs-books-recommender-analysis-eda/notebook\n",
    "2. https://www.kaggle.com/code/gspmoreira/recommender-systems-in-python-101#Conclusion\n",
    "- In this project, we had to use ChatGPT to debug some errors encountered in our analysis, which significantly accelerated our development process of the recommender system.\n",
    "- Author contributions: <br>\n",
    "Nurbek: Popularity filtering & Content-based   <br>\n",
    "Asset: Collaborative filtering & Top N accuracy metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Review Questions\n",
    "1. What is a recommender system, and why is it relevant in today's digital world?\n",
    "2. Can you describe the distinction between collaborative and content-based filtering?\n",
    "3. What role does popularity-based filtering play in recommender systems?\n",
    "4. Describe how content-based filtering recommends items to users.\n",
    "5. Describe how collaborative filtering recommends items to users.\n",
    "6. What are Top-N accuracy metrics, and why are they important in evaluating recommender systems?\n",
    "7. What is Spearman rank correlation coefficient? How does it work in context of book recommendation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
