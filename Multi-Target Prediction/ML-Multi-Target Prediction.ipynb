{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning 2 for Masters Students\n",
    "# Topic: Multi-Target Prediction\n",
    "### Group Members: Daniel Gombas, Amirhooshang Navaei\n",
    "### Date: 03/19/2024\n",
    "_____________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction\n",
    "\n",
    "Multi-target prediction, also known as multi-output or multi-task learning, is an important area in machine learning that addresses problems where the goal is to predict multiple dependent variables (targets) simultaneously from a set of input variables (features). This approach is particularly relevant in complex real-world scenarios where multiple outcomes are interrelated and can influence each other.\n",
    "\n",
    "### Problem Addressed:\n",
    "**Complex Interdependencies**: Many real-world problems involve predicting multiple outcomes that may be related or dependent on each other. Traditional single-target prediction models might ignore these dependencies, potentially leading to suboptimal performance.  \n",
    "\n",
    "**Efficiency**: By predicting multiple targets simultaneously, multi-target models can leverage shared information among targets, reducing the need to train separate models for each target. This can lead to more efficient use of computational resources and data.  \n",
    "\n",
    "**Improved Generalization**: Multi-target models can potentially improve prediction accuracy by learning shared representations that capture underlying patterns relevant to multiple targets, thus enhancing the model's generalization capabilities.\n",
    "\n",
    "### Intuition:\n",
    "**Shared Representation**: The core intuition behind multi-target prediction is that the targets share some common underlying factors. By learning these shared representations, the model can make more informed predictions for each target.  \n",
    "\n",
    "**Exploiting Correlations**: Multi-target models aim to exploit the correlations and interactions between targets. For example, in a health-related dataset, predicting multiple health outcomes simultaneously may yield better predictions than treating each outcome independently, as many health metrics are interrelated.  \n",
    "\n",
    "**Joint Learning**: Multi-target prediction is essentially a form of joint learning, where the model learns to optimize the predictions for multiple targets in a coordinated manner. This joint learning approach can help in uncovering insights that may not be apparent when targets are considered in isolation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Preliminaries\n",
    "\n",
    "Two datasets have been considered for this project:\n",
    "\n",
    "* Enzyme substrates - Multi-Label Classification\n",
    "* Energy efficiency in Buildings - Multi-target Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Basic Use-case\n",
    "The principles of multi-target prediction apply to many domains, such as genomics, finance, and recommendation systems, where multiple outcomes or variables are of interest are not independent of each other.  \n",
    "\n",
    "One of the most prototypical and illustrative use cases of multi-target prediction is in environmental modeling, specifically in predicting various aspects of weather or climate conditions from a set of input variables. In this context, multi-target prediction models can simultaneously forecast multiple weather parameters, such as temperature, humidity, precipitation, wind speed, and air pressure, from historical and current weather data.\n",
    "\n",
    "### Why Environmental Modeling Suits Multi-Target Prediction:\n",
    "**Interrelated Targets**: Weather variables are naturally interrelated; for example, air pressure affects temperature and wind patterns, while humidity can influence precipitation levels. Multi-target prediction models can leverage these relationships to improve the accuracy of forecasts.  \n",
    "\n",
    "**Data Efficiency**: Environmental datasets can be massive and complex, making efficient data use crucial. Multi-target prediction allows for shared learning across related targets, making better use of available data.  \n",
    "\n",
    "**Predictive Performance**: By considering multiple weather parameters simultaneously, multi-target models can capture the complex interactions between different elements of the weather system, potentially leading to more accurate and reliable predictions.  \n",
    "\n",
    "**Operational Efficiency**: For weather forecasting agencies and environmental researchers, the ability to produce multiple forecasts simultaneously from a single model can greatly improve operational efficiency and reduce computational costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Show-case - Drug Discovery\n",
    "\n",
    "A compelling use case where multi-target prediction can make a significant difference compared to training several single-target models is in drug discovery and personalized medicine, particularly in predicting the effects of drugs on multiple genetic markers or cellular responses simultaneously.  \n",
    "\n",
    "### Context and Challenge:\n",
    "In drug discovery and personalized medicine, it's crucial to understand how different compounds interact with various genetic markers or cellular processes. A single drug can have multiple effects, impacting various genes, proteins, or pathways. Traditional approaches might involve building separate models to predict the effect of compounds on each marker or response, which can be inefficient and may ignore the interdependencies between these effects.  \n",
    "\n",
    "### Multi-Target Prediction in Drug Discovery:\n",
    "**Simultaneous Prediction**: Multi-target prediction models can be trained to predict the effects of compounds on multiple genetic markers or cellular responses at once. This is particularly valuable in high-throughput screening processes where thousands of compounds are tested for their effects on a wide range of targets.  \n",
    "\n",
    "**Capturing Interdependencies**: By predicting multiple targets simultaneously, these models can capture the complex interactions and dependencies between different cellular responses or genetic markers, leading to a more holistic understanding of compound effects.  \n",
    "\n",
    "**Efficiency and Cost-Effectiveness**: Multi-target models can reduce the computational and time costs associated with training and maintaining numerous single-target models. In drug discovery, where time and resources are critical, this can be a substantial advantage.  \n",
    "\n",
    "**Improved Predictive Performance**: Leveraging shared information across multiple targets can enhance predictive performance, especially in cases where data for some targets might be sparse but related targets have abundant data.  \n",
    "\n",
    "### Impact and Difference:\n",
    "In the context of drug discovery and personalized medicine, using multi-target prediction can significantly accelerate the discovery process and enhance the understanding of drug effects. It allows researchers to efficiently identify compounds with desired effects across multiple targets, facilitating the development of more effective and safer drugs. Moreover, in personalized medicine, understanding the multi-faceted interactions between drugs and an individual's unique genetic makeup can lead to more tailored and effective treatments, ultimately improving patient outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Results and Analysis\n",
    "Case I: Multi-Label Classification: [Enzyme substrates](https://www.kaggle.com/datasets/gopalns/ec-mixed-class?select=mixed_desc.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIDs</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>...</th>\n",
       "      <th>M504</th>\n",
       "      <th>M505</th>\n",
       "      <th>M506</th>\n",
       "      <th>M507</th>\n",
       "      <th>M508</th>\n",
       "      <th>M509</th>\n",
       "      <th>M510</th>\n",
       "      <th>M511</th>\n",
       "      <th>M512</th>\n",
       "      <th>EC1_EC2_EC3_EC4_EC5_EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1_1_1_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1_1_1_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1_1_1_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_1_1_0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_1_1_1_0_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CIDs  M1  M2  M3  M4  M5  M6  M7  M8  M9  ...  M504  M505  M506  M507  \\\n",
       "0  C00009   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "1  C00013   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "2  C00014   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "3  C00017   0   1   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "4  C00022   0   0   0   0   0   0   0   0   0  ...     0     0     1     0   \n",
       "\n",
       "   M508  M509  M510  M511  M512  EC1_EC2_EC3_EC4_EC5_EC6  \n",
       "0     0     0     0     0     0              1_1_1_1_0_1  \n",
       "1     0     0     0     0     0              1_1_1_1_0_1  \n",
       "2     0     0     0     0     0              1_1_1_1_0_1  \n",
       "3     0     0     0     0     0              0_1_1_0_0_0  \n",
       "4     0     0     0     0     0              1_1_1_1_0_1  \n",
       "\n",
       "[5 rows x 514 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data2 = pd.read_csv(\"mixed_ecfp.csv\")\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"EC1_EC2_EC3_EC4_EC5_EC6\" column into separate columns\n",
    "targets_split = data2['EC1_EC2_EC3_EC4_EC5_EC6'].str.split('_', expand=True)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "targets_split.columns = ['EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6']\n",
    "\n",
    "# Concatenate the new target columns back to the original dataframe\n",
    "data2 = pd.concat([data2.drop('EC1_EC2_EC3_EC4_EC5_EC6', axis=1), targets_split], axis=1)\n",
    "\n",
    "# dropp the first column\n",
    "data2 = data2.drop(data2.columns[0], axis=1)\n",
    "\n",
    "# Separate features\n",
    "X = data2.loc[:, 'M1':'M512']  # Adjust the column names if needed\n",
    "\n",
    "# Separate target variables\n",
    "Y = data2[['EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6']]\n",
    "\n",
    "Y1 = Y['EC1']\n",
    "Y2 = Y['EC2']\n",
    "Y3 = Y['EC3']\n",
    "Y4 = Y['EC4']\n",
    "Y5 = Y['EC5']\n",
    "Y6 = Y['EC6']\n",
    "\n",
    "# convert the Y to int\n",
    "data2 = data2.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Multiple Single-Target Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1: 0.6201923076923077\n",
      "Accuracy2: 0.625\n",
      "Accuracy3: 0.6826923076923077\n",
      "Accuracy4: 0.7211538461538461\n",
      "Accuracy5: 0.875\n",
      "Accuracy6: 0.8509615384615384\n",
      "Confusion matrix1: \n",
      " [[53 44]\n",
      " [35 76]]\n",
      "Confusion matrix2: \n",
      " [[38 50]\n",
      " [28 92]]\n",
      "Confusion matrix3: \n",
      " [[119  23]\n",
      " [ 43  23]]\n",
      "Confusion matrix4: \n",
      " [[136  10]\n",
      " [ 48  14]]\n",
      "Confusion matrix5: \n",
      " [[177   6]\n",
      " [ 20   5]]\n",
      "Confusion matrix6: \n",
      " [[175   7]\n",
      " [ 24   2]]\n",
      "Mean accuracy: 0.7291666666666666\n",
      "Confusion matrix aggregate: \n",
      " [[698 140]\n",
      " [198 212]]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y1_train, Y1_test = train_test_split(X, Y1, test_size=0.2, random_state=42)\n",
    "X_train, X_test, Y2_train, Y2_test = train_test_split(X, Y2, test_size=0.2, random_state=42)\n",
    "X_train, X_test, Y3_train, Y3_test = train_test_split(X, Y3, test_size=0.2, random_state=42)\n",
    "X_train, X_test, Y4_train, Y4_test = train_test_split(X, Y4, test_size=0.2, random_state=42)\n",
    "X_train, X_test, Y5_train, Y5_test = train_test_split(X, Y5, test_size=0.2, random_state=42)\n",
    "X_train, X_test, Y6_train, Y6_test = train_test_split(X, Y6, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model1.fit(X_train, Y1_train)\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2.fit(X_train, Y2_train)\n",
    "\n",
    "model3 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model3.fit(X_train, Y3_train)\n",
    "\n",
    "model4 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model4.fit(X_train, Y4_train)\n",
    "\n",
    "model5 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model5.fit(X_train, Y5_train)\n",
    "\n",
    "model6 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model6.fit(X_train, Y6_train)\n",
    "\n",
    "# Make predictions\n",
    "Y1_pred = model1.predict(X_test)\n",
    "Y2_pred = model2.predict(X_test)\n",
    "Y3_pred = model3.predict(X_test)\n",
    "Y4_pred = model4.predict(X_test)\n",
    "Y5_pred = model5.predict(X_test)\n",
    "Y6_pred = model6.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy1 = accuracy_score(Y1_test, Y1_pred)\n",
    "accuracy2 = accuracy_score(Y2_test, Y2_pred)\n",
    "accuracy3 = accuracy_score(Y3_test, Y3_pred)\n",
    "accuracy4 = accuracy_score(Y4_test, Y4_pred)\n",
    "accuracy5 = accuracy_score(Y5_test, Y5_pred)\n",
    "accuracy6 = accuracy_score(Y6_test, Y6_pred)\n",
    "\n",
    "print(f'Accuracy1: {accuracy1}')\n",
    "print(f'Accuracy2: {accuracy2}')\n",
    "print(f'Accuracy3: {accuracy3}')\n",
    "print(f'Accuracy4: {accuracy4}')\n",
    "print(f'Accuracy5: {accuracy5}')\n",
    "print(f'Accuracy6: {accuracy6}')\n",
    "\n",
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix1 = confusion_matrix(Y1_test, Y1_pred)\n",
    "confusion_matrix2 = confusion_matrix(Y2_test, Y2_pred)\n",
    "confusion_matrix3 = confusion_matrix(Y3_test, Y3_pred)\n",
    "confusion_matrix4 = confusion_matrix(Y4_test, Y4_pred)\n",
    "confusion_matrix5 = confusion_matrix(Y5_test, Y5_pred)\n",
    "confusion_matrix6 = confusion_matrix(Y6_test, Y6_pred)\n",
    "\n",
    "print(f'Confusion matrix1: \\n {confusion_matrix1}')\n",
    "print(f'Confusion matrix2: \\n {confusion_matrix2}')\n",
    "print(f'Confusion matrix3: \\n {confusion_matrix3}')\n",
    "print(f'Confusion matrix4: \\n {confusion_matrix4}')\n",
    "print(f'Confusion matrix5: \\n {confusion_matrix5}')\n",
    "print(f'Confusion matrix6: \\n {confusion_matrix6}')\n",
    "\n",
    "# print the mean accuracy for all the models\n",
    "mean_accuracy = (accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy5 + accuracy6) / 6\n",
    "print(f'Mean accuracy: {mean_accuracy}')\n",
    "\n",
    "# print the aggregate confusion matrix for all the models\n",
    "confusion_matrix_aggregate = confusion_matrix1 + confusion_matrix2 + confusion_matrix3 + confusion_matrix4 + confusion_matrix5 + confusion_matrix6\n",
    "\n",
    "print(f'Confusion matrix aggregate: \\n {confusion_matrix_aggregate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Multi-label Classification using Scikit-MultiLearn Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label EC1: 0.6201923076923077\n",
      "Accuracy for label EC2: 0.6201923076923077\n",
      "Accuracy for label EC3: 0.7019230769230769\n",
      "Accuracy for label EC4: 0.7211538461538461\n",
      "Accuracy for label EC5: 0.8701923076923077\n",
      "Accuracy for label EC6: 0.8461538461538461\n",
      "Confusion Matrix for label EC1:\n",
      "[[53 44]\n",
      " [35 76]]\n",
      "\n",
      "Confusion Matrix for label EC2:\n",
      "[[36 52]\n",
      " [27 93]]\n",
      "\n",
      "Confusion Matrix for label EC3:\n",
      "[[121  21]\n",
      " [ 41  25]]\n",
      "\n",
      "Confusion Matrix for label EC4:\n",
      "[[133  13]\n",
      " [ 45  17]]\n",
      "\n",
      "Confusion Matrix for label EC5:\n",
      "[[176   7]\n",
      " [ 20   5]]\n",
      "\n",
      "Confusion Matrix for label EC6:\n",
      "[[173   9]\n",
      " [ 23   3]]\n",
      "\n",
      "Multilabel Confusion Matrix:\n",
      " [[[ 53  44]\n",
      "  [ 35  76]]\n",
      "\n",
      " [[ 36  52]\n",
      "  [ 27  93]]\n",
      "\n",
      " [[121  21]\n",
      "  [ 41  25]]\n",
      "\n",
      " [[133  13]\n",
      "  [ 45  17]]\n",
      "\n",
      " [[176   7]\n",
      "  [ 20   5]]\n",
      "\n",
      " [[173   9]\n",
      "  [ 23   3]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, multilabel_confusion_matrix\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize ClassifierChain with RandomForestClassifier\n",
    "classifier = ClassifierChain(RandomForestClassifier(random_state=42))\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# convert predictions to a dense format\n",
    "predictions_dense = predictions.toarray() if hasattr(predictions, \"toarray\") else predictions\n",
    "\n",
    "# Calculate accuracy for each label\n",
    "accuracy_scores = [accuracy_score(y_test.iloc[:, i], predictions_dense[:, i]) for i in range(y_test.shape[1])]\n",
    "\n",
    "# Calculate confusion matrix for each label\n",
    "confusion_matrices = [confusion_matrix(y_test.iloc[:, i], predictions_dense[:, i]) for i in range(y_test.shape[1])]\n",
    "\n",
    "# Calculate multilabel confusion matrix\n",
    "multi_conf_matrix = multilabel_confusion_matrix(y_test, predictions_dense)\n",
    "\n",
    "# Print accuracy scores for each label\n",
    "for i, score in enumerate(accuracy_scores, 1):\n",
    "    print(f\"Accuracy for label EC{i}: {score}\")\n",
    "\n",
    "# Analyze confusion matrices\n",
    "# For individual labels:\n",
    "for i, cm in enumerate(confusion_matrices, 1):\n",
    "    print(f\"Confusion Matrix for label EC{i}:\\n{cm}\\n\")\n",
    "\n",
    "# For the multilabel confusion matrix:\n",
    "print(\"Multilabel Confusion Matrix:\\n\", multi_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7299679487179486\n",
      "Confusion matrix aggregate: \n",
      " [[692 146]\n",
      " [191 219]]\n"
     ]
    }
   ],
   "source": [
    "# print the mean accuracy for all the models\n",
    "mean_accuracy_multilabel = np.mean(accuracy_scores)\n",
    "print(f'Mean accuracy: {mean_accuracy_multilabel}')\n",
    "\n",
    "# print the aggregate confusion matrix for all the models\n",
    "confusion_matrix_aggregate_multilabel = np.sum(confusion_matrices, axis=0)\n",
    "\n",
    "print(f'Confusion matrix aggregate: \\n {confusion_matrix_aggregate_multilabel}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Clustering trees - using SPYCT Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6298076923076923, 0.6153846153846154, 0.6971153846153846, 0.7019230769230769, 0.8798076923076923, 0.875]\n",
      "[array([[45, 52],\n",
      "       [25, 86]], dtype=int64), array([[ 18,  70],\n",
      "       [ 10, 110]], dtype=int64), array([[138,   4],\n",
      "       [ 59,   7]], dtype=int64), array([[146,   0],\n",
      "       [ 62,   0]], dtype=int64), array([[183,   0],\n",
      "       [ 25,   0]], dtype=int64), array([[182,   0],\n",
      "       [ 26,   0]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "import spyct\n",
    "\n",
    "y_test_spyct_0 = y_test.values\n",
    "\n",
    "# Create a model\n",
    "model = spyct.Model(num_trees=100, max_depth=4, random_state=123)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_spyct = model.predict(X_test.values)\n",
    "\n",
    "# rounding the values in y_pred_spyct using the threshold of 0.5\n",
    "y_pred_spyct_rounded = y_pred_spyct.round()\n",
    "\n",
    "# Calculate accuracy for each label\n",
    "accuracy_scores_spyct = [accuracy_score(y_test.iloc[:, i], y_pred_spyct_rounded[:, i]) for i in range(y_test.shape[1])]\n",
    "print(accuracy_scores_spyct)\n",
    "\n",
    "\n",
    "# Calculate confusion matrix for each label\n",
    "confusion_matrices_spyct = [confusion_matrix(y_test.iloc[:, i], y_pred_spyct_rounded[:, i]) for i in range(y_test.shape[1])]\n",
    "print(confusion_matrices_spyct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.733173076923077\n",
      "Confusion matrix aggregate: \n",
      " [[712 126]\n",
      " [207 203]]\n"
     ]
    }
   ],
   "source": [
    "# print the mean accuracy for all the models\n",
    "mean_accuracy_spyct = np.mean(accuracy_scores_spyct)\n",
    "\n",
    "print(f'Mean accuracy: {mean_accuracy_spyct}')\n",
    "\n",
    "# print the aggregate confusion matrix for all the models\n",
    "confusion_matrix_aggregate_spyct = np.sum(confusion_matrices_spyct, axis=0)\n",
    "\n",
    "print(f'Confusion matrix aggregate: \\n {confusion_matrix_aggregate_spyct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC3</th>\n",
       "      <th>EC4</th>\n",
       "      <th>EC5</th>\n",
       "      <th>EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EC1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.165158</td>\n",
       "      <td>-0.289396</td>\n",
       "      <td>0.046609</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>0.087381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC2</th>\n",
       "      <td>-0.165158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.094042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC3</th>\n",
       "      <td>-0.289396</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096364</td>\n",
       "      <td>-0.050693</td>\n",
       "      <td>-0.017205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC4</th>\n",
       "      <td>0.046609</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>-0.096364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114881</td>\n",
       "      <td>0.178339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC5</th>\n",
       "      <td>-0.003054</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>-0.050693</td>\n",
       "      <td>0.114881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC6</th>\n",
       "      <td>0.087381</td>\n",
       "      <td>0.094042</td>\n",
       "      <td>-0.017205</td>\n",
       "      <td>0.178339</td>\n",
       "      <td>0.046642</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EC1       EC2       EC3       EC4       EC5       EC6\n",
       "EC1  1.000000 -0.165158 -0.289396  0.046609 -0.003054  0.087381\n",
       "EC2 -0.165158  1.000000  0.031990 -0.009563  0.043308  0.094042\n",
       "EC3 -0.289396  0.031990  1.000000 -0.096364 -0.050693 -0.017205\n",
       "EC4  0.046609 -0.009563 -0.096364  1.000000  0.114881  0.178339\n",
       "EC5 -0.003054  0.043308 -0.050693  0.114881  1.000000  0.046642\n",
       "EC6  0.087381  0.094042 -0.017205  0.178339  0.046642  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the correlation between the labels\n",
    "Y = Y.astype(int)\n",
    "\n",
    "correlation = Y.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case II: Multi-target regression: \n",
    "- All target variables are numeric and continuous.\n",
    "- Several approaches can be take to solve the problem.\n",
    "\n",
    "### Dataset information: \n",
    "* Assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.\n",
    "-   Number of features: 8\n",
    "-   Number of targets: 2\n",
    "-   Number of instances: 768\n",
    "-   Features types: Integer, Real\n",
    "-   Target types: Real\n",
    "\n",
    "**Additional information:**  \n",
    "This dataset is used for performing energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.\n",
    "\n",
    "**Source**: [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/242/energy+efficiency)\n",
    "\n",
    "### Method 1: Multiple Single-Target Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Engeff.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4927568965432238, 1.3538390086578387, 1.8465959052010625)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Splitting the dataset into features and targets\n",
    "X = data.drop(['Y1', 'Y2'], axis=1)\n",
    "y1 = data['Y1']\n",
    "y2 = data['Y2']\n",
    "\n",
    "# Splitting the dataset into the training and testing set\n",
    "X_train_1, X_test_1, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=123)\n",
    "X_train_2, X_test_2, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=123)\n",
    "\n",
    "rf_regressor_y1 = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "rf_regressor_y2 = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "\n",
    "rf_regressor_y1.fit(X_train_1, y1_train)\n",
    "rf_regressor_y2.fit(X_train_2, y2_train)\n",
    "\n",
    "y1_pred = rf_regressor_y1.predict(X_test_1)\n",
    "y2_pred = rf_regressor_y2.predict(X_test_2)\n",
    "\n",
    "rmse_y1 = sqrt(mean_squared_error(y1_test, y1_pred))\n",
    "rmse_y2 = sqrt(mean_squared_error(y2_test, y2_pred))\n",
    "\n",
    "(rmse_y1, rmse_y2, (rmse_y1 + rmse_y2) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Multi-Target Regression using Scikit Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47121350132521606, 1.425401076434734, 1.8966145777599501)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into features and targets\n",
    "X = data.drop(['Y1', 'Y2'], axis=1)\n",
    "y = data[['Y1', 'Y2']]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Initializing and training the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculating the RMSE for each target\n",
    "rmse_y1 = sqrt(mean_squared_error(y_test['Y1'], y_pred[:, 0]))\n",
    "rmse_y2 = sqrt(mean_squared_error(y_test['Y2'], y_pred[:, 1]))\n",
    "\n",
    "(rmse_y1, rmse_y2, rmse_y1 + rmse_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Clustering trees - using SPYCT Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44593994176199037, 1.3962173388169186, 1.8421572805789088)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spyct\n",
    "\n",
    "y_test_spyct = y_test.values\n",
    "\n",
    "# Create a model\n",
    "model = spyct.Model(splitter=\"grad\", num_trees=200, random_state=123)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_spyct = model.predict(X_test.values)\n",
    "\n",
    "# Calculating the RMSE for each target\n",
    "rmse_y1_spyct = sqrt(mean_squared_error(y_test_spyct[:, 0], y_pred_spyct[:, 0]))\n",
    "rmse_y2_spyct = sqrt(mean_squared_error(y_test_spyct[:, 1], y_pred_spyct[:, 1]))\n",
    "\n",
    "(rmse_y1_spyct, rmse_y2_spyct, (rmse_y1_spyct+ rmse_y2_spyct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y2</th>\n",
       "      <td>0.975862</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y1        Y2\n",
       "Y1  1.000000  0.975862\n",
       "Y2  0.975862  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the correlation between the two targets\n",
    "data[['Y1', 'Y2']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Caution\n",
    "### Situations Where Multi-Target Prediction Might Not Be Ideal:\n",
    "**Unrelated Targets**: If the targets are largely independent, with little to no correlation, multi-target prediction might not offer significant benefits over single-target models and could even complicate the modeling process unnecessarily.  \n",
    "**Highly Correlated Targets**: If target variables are highly correlated, multi-target prediction will not increase the accuracy compared to single-target predictions. \n",
    "\n",
    "**Vastly Different Scales or Types of Targets**: When targets have vastly different scales or are of different types (e.g., one is categorical, and another is continuous), it might be challenging to design a single model that effectively predicts all targets without bias or scale issues.  \n",
    "\n",
    "### Common Pitfalls:\n",
    "**Overfitting**: Just like any machine learning model, multi-target models can suffer from overfitting, especially if they're complex and the data is not sufficient to support the learning of multiple targets. Regularization, proper validation, and complexity control are essential to mitigate this risk.  \n",
    "\n",
    "**Data Leakage**: In multi-target settings, there's a risk of data leakage between targets, especially if some targets could be predictors for others. This could lead to overly optimistic performance estimates. Proper data handling and validation strategies are crucial to prevent this.  \n",
    "\n",
    "**Evaluation Complexity**: Evaluating the performance of multi-target models can be more complex than single-target models because you need to consider the performance across all targets. Selecting appropriate and comprehensive evaluation metrics is key.  \n",
    "\n",
    "**Computational Cost**: While multi-target models can be efficient by sharing representations among targets, they can also be computationally intensive, especially if the number of targets is large and the model architecture is complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Summary\n",
    "### Relevance in Machine Learning:\n",
    "**Efficiency and Performance**: Multi-target models can be more efficient than training separate models for each target, both in terms of computational resources and data usage. They often achieve better performance by exploiting the relationships among targets.  \n",
    "\n",
    "**Complex Problem Solving**: Multi-target prediction is essential for complex problems in fields such as environmental science, health, finance, and more, where multiple factors are interrelated and need to be predicted simultaneously.  \n",
    "\n",
    "**Advanced Insights**: By predicting multiple targets at once, these models can provide more holistic insights into the underlying problem, which can be critical for decision-making in various applications.  \n",
    "\n",
    "### Take-home Messages:\n",
    "**Interrelated Targets**: Consider multi-target prediction when your targets are interrelated. The approach is most beneficial when the prediction of one target can inform the prediction of another.  \n",
    "\n",
    "**Model Complexity**: Be mindful of the model complexity. While multi-target models can leverage shared information, they can also become overly complex and prone to overfitting. Proper regularization and validation are key.  \n",
    "\n",
    "**Data Considerations**: Ensure your dataset is sufficient and appropriate for multi-target prediction. The quality and quantity of data, along with how well it represents the interrelations among targets, are crucial for the success of these models.  \n",
    "\n",
    "**Evaluation Strategies**: Adopt comprehensive evaluation strategies. Given the multiple outcomes, it's important to use evaluation metrics that can adequately assess the model's performance across all targets.  \n",
    "\n",
    "**Practicality and Relevance**: Assess the practicality and relevance of multi-target prediction for your specific problem. While it offers significant advantages in many scenarios, it's not a one-size-fits-all solution and might not be suitable for problems with independent targets or where the complexity outweighs the benefits.  \n",
    "\n",
    "In summary, multi-target prediction is a powerful approach in machine learning for addressing complex problems with interrelated targets, offering efficiency and potentially enhanced predictive performance. However, it requires careful consideration of the problem context, data quality, model complexity, and evaluation strategies to be effectively implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: References and Resources\n",
    "- Papers:\n",
    "    1. Jasmin Bogatinovski, Ljupčo Todorovski, Sašo Džeroski, Dragi Kocev (2022): Comprehensive comparative study of multi-label classification methods, Expert Systems with Applications, Volume 203\n",
    "    2. Dragi Kocev, Celine Vens, Jan Struyf, Sašo Džeroski (2013): Tree ensembles for predicting structured outputs, Pattern Recognition, Volume 46, Issue 3\n",
    "\n",
    "- Blogs: \n",
    "    * https://la.mathworks.com/help/deeplearning/ug/multilabel-image-classification-using-deep-learning.html\n",
    "\n",
    "- Data Sources:\n",
    "    1. Enzyme Substrates: Kaggle - [Structural information dataset](https://www.kaggle.com/datasets/gopalns/ec-mixed-class?select=mixed_desc.csv)\n",
    "    2. Energy Efficiency: [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/242/energy+efficiency)\n",
    "- Generative AI tools: \n",
    "    1. ChatGPT  \n",
    "    2. Copilot\n",
    "- Author contributions:\n",
    "    1. Amirhooshang Navaei: Basics of Multi-Target Prediction, finding datasources, Code\n",
    "    2. Daneil Gombas: Papers, technical aspects of topic, code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Review Questions\n",
    "\n",
    "1. What is multi-target prediction, and how does it differ from single-target prediction?  \n",
    "\n",
    "2. Can you explain the difference between multi-class classification and multi-label classification?  \n",
    "\n",
    "3. Describe a real-world application where multi-target prediction is particularly useful. Why is it preferred over single-target models in this scenario?  \n",
    "\n",
    "4. What are some common domains or fields where multi-target prediction models are employed?  \n",
    "\n",
    "5. How do multi-target prediction models leverage the relationships among multiple targets to improve prediction accuracy?  \n",
    "\n",
    "6. Discuss at least one machine learning algorithm that can be adapted for multi-target prediction. How does it work?\n",
    "\n",
    "7. What are some important considerations when preparing data for a multi-target prediction model?  \n",
    "\n",
    "8. How might the preprocessing steps for a multi-target prediction model differ from those of a single-target prediction model?  \n",
    "\n",
    "9. Identify and explain a common pitfall in multi-target prediction and suggest a way to mitigate it.  \n",
    "\n",
    "10. Why is overfitting a concern in multi-target prediction, and what strategies can be used to prevent it?  \n",
    "\n",
    "11. What are some key metrics for evaluating the performance of multi-target prediction models? How do these differ from single-target evaluation metrics? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
